# Preprocessing Module - SciPy Layer

M√≥dulo de pr√©-processamento matem√°tico de dados de telemetria F1 usando **SciPy**. Este m√≥dulo transforma dados brutos e dessincronizados do FastF1 em sinais matem√°ticos limpos e compar√°veis para an√°lise de Machine Learning.

## üéØ Objetivo

O SciPy atua como **motor matem√°tico de pr√©-processamento e engenharia de features**, preparando dados para:
- **Scikit-learn**: modelos de clustering e detec√ß√£o de anomalias
- **Ruptures**: detec√ß√£o de pontos de mudan√ßa (degrada√ß√£o de pneus)

## üì¶ Componentes

> **Nota sobre Configura√ß√£o**: Todos os par√¢metros (num_points, kernel_size, contamination, etc.) s√£o centralizados em `config.yaml` na raiz do projeto. Voc√™ pode customizar os valores padr√£o editando este arquivo.

### 1. Sincroniza√ß√£o de Telemetria (`interpolation.py`)

**Problema**: Dados de telemetria chegam dessincronizados - diferentes pilotos t√™m medi√ß√µes em pontos diferentes da pista.

**Solu√ß√£o**: Interpola√ß√£o c√∫bica spline para criar um grid comum de dist√¢ncia.

**Ferramentas**:
- `scipy.interpolate.make_interp_spline`
- `scipy.interpolate.CubicSpline`

**Fun√ß√µes**:
```python
synchronize_telemetry(
    telemetry: pd.DataFrame,
    track_length: float,
    num_points: int = 5000,
) -> pd.DataFrame
```

**Exemplo**:
```python
from src.preprocessing.interpolation import synchronize_telemetry

# Sincronizar telemetria de um piloto
ver_telemetry = lap.get_telemetry()
synchronized = synchronize_telemetry(
    ver_telemetry,
    track_length=5281.0,  # Monaco
    num_points=5000
)

# Agora pode comparar diretamente com outros pilotos
ham_synchronized = synchronize_telemetry(ham_telemetry, 5281.0, 5000)
speed_delta = synchronized['Speed'] - ham_synchronized['Speed']
```

**Resultado**:
- Matriz onde cada linha = uma volta
- Cada coluna = um ponto exato da pista
- Pronta para compara√ß√µes diretas e c√°lculos de delta

---

### 2. Tratamento de Sinal (`signal_processing.py`)

**Problema**: Sensores t√™m ru√≠do - picos repentinos que n√£o representam a√ß√µes reais do piloto.

**Solu√ß√£o**: Filtros de processamento de sinais para suavizar curvas preservando informa√ß√£o importante.

**Ferramentas**:
- `scipy.signal.medfilt` - Remove outliers pontuais preservando bordas
- `scipy.signal.savgol_filter` - Suaviza√ß√£o e c√°lculo de derivadas

**Fun√ß√µes**:
```python
clean_signal(
    signal: np.ndarray,
    method: str = "median",  # ou "savgol"
    kernel_size: int = 5,
) -> np.ndarray

calculate_derivative(
    signal: np.ndarray,
    delta_x: float = 1.0,
    smooth: bool = True,
) -> np.ndarray

apply_telemetry_pipeline(
    telemetry_dict: dict[str, np.ndarray],
    noise_reduction: bool = True,
    outlier_removal: bool = True,
    calculate_derivatives: bool = False,
) -> dict[str, np.ndarray]
```

**Exemplo**:
```python
from src.preprocessing.signal_processing import apply_telemetry_pipeline

telemetry = {
    'Speed': speed_array,
    'Throttle': throttle_array,
    'Brake': brake_array,
}

# Pipeline completo
processed = apply_telemetry_pipeline(
    telemetry,
    noise_reduction=True,      # Remove ru√≠do
    outlier_removal=True,       # Remove spikes
    calculate_derivatives=True, # Calcula acelera√ß√£o
)

# Resultado inclui:
# - 'Speed', 'Throttle', 'Brake' (limpos)
# - 'Speed_derivative' (acelera√ß√£o)
# - 'Throttle_derivative', 'Brake_derivative'
```

**Resultado**:
- Dados "polidos" onde varia√ß√µes representam apenas f√≠sica do carro
- Facilita detec√ß√£o de anomalias reais pelo Isolation Forest

---

### 3. Engenharia de Features (`feature_engineering/`)

**Problema**: Identificar outliers, preparar dados para ML e extrair features espec√≠ficas de F1.

**Solu√ß√£o**: M√≥dulo organizado em 3 subm√≥dulos especializados por responsabilidade.

#### 3.1 Features Estat√≠sticas (`feature_engineering/statistical.py`)

An√°lise estat√≠stica e degrada√ß√£o de pneus usando `scipy.stats`.

**Ferramentas**:
- `scipy.stats.zscore` - Normaliza√ß√£o e detec√ß√£o de outliers
- `scipy.stats.describe` - Estat√≠sticas descritivas
- `scipy.stats.linregress` - Taxa de degrada√ß√£o

**Fun√ß√µes**:
```python
from src.preprocessing.feature_engineering.statistical import (
    calculate_statistical_features,
    calculate_degradation_rate,
    calculate_descriptive_statistics,
    enrich_dataframe_with_stats,
)
```

#### 3.2 Pr√©-processamento de Dom√≠nio F1 (`feature_engineering/domain.py`)

Transforma√ß√£o de dados espec√≠ficos de corrida (race control, clima, resultados).

**Fun√ß√µes**:
```python
from src.preprocessing.feature_engineering.domain import (
    preprocess_race_control,  # Safety car, bandeiras, penalidades
    preprocess_weather,        # Temperatura, chuva, tend√™ncias
    preprocess_results,        # Classifica√ß√£o, performance scores
)
```

#### 3.3 Prepara√ß√£o para ML (`feature_engineering/ml_prep.py`)

Imputa√ß√£o, encoding e escalonamento para Scikit-learn.

**Fun√ß√µes**:
```python
from src.preprocessing.feature_engineering.ml_prep import (
    impute_missing_values,        # SimpleImputer / KNNImputer
    encode_categorical_variables, # OneHotEncoder
    scale_features,               # StandardScaler / RobustScaler
)
```

**Backward Compatibility**: Todas as fun√ß√µes tamb√©m podem ser importadas do m√≥dulo principal:
```python
# Ambos funcionam:
from src.preprocessing.feature_engineering import calculate_statistical_features
from src.preprocessing.feature_engineering.statistical import calculate_statistical_features
```

**Exemplo - Features Estat√≠sticas**:
```python
from src.preprocessing.feature_engineering import enrich_dataframe_with_stats

# DataFrame com tempos de volta
laps_df = session.laps[['LapNumber', 'LapTime', 'Driver', 'Compound']]

# Adicionar features estat√≠sticas
enriched = enrich_dataframe_with_stats(
    laps_df,
    value_column='LapTime',
    group_by=['Driver', 'Compound'],
    include_degradation=True
)

# Colunas adicionadas:
# - z_score: score normalizado
# - is_outlier: flag para |z| > 3
# - group_mean, group_std: estat√≠sticas do grupo
# - degradation_slope: taxa de degrada√ß√£o (s/lap)
# - degradation_r_squared: qualidade do fit
# - degradation_intercept: tempo estimado primeira volta

# Filtrar outliers
clean_laps = enriched[~enriched['is_outlier']]
```

**Exemplo - Pr√©-processamento para ML**:
```python
from src.preprocessing.feature_engineering import (
    impute_missing_values,
    encode_categorical_variables,
    scale_features,
)

# Pipeline completo de prepara√ß√£o para ML
laps_imputed = impute_missing_values(laps_df, strategy='median')
laps_encoded = encode_categorical_variables(laps_imputed, categorical_columns=['Compound'])
laps_scaled = scale_features(laps_encoded, scaler_type='robust')

# Agora pronto para Scikit-learn (K-Means, Isolation Forest, etc.)
```

**Resultado**:
- DataFrame com flags de outliers
- Features de degrada√ß√£o para Pydantic
- Entrada limpa para Scikit-learn

---

## üîÑ Fluxo Completo

```python
# 1. Entrada: Dados brutos do FastF1
session = fastf1.get_session(2024, 'Monaco', 'R')
session.load()
laps = session.laps.pick_driver('VER')

# 2. Processamento SciPy

# 2.1 - Interpola√ß√£o: Sincronizar telemetria
from src.preprocessing.interpolation import synchronize_telemetry
synchronized = synchronize_telemetry(
    telemetry,
    track_length=session.get_circuit_info().total_distance
)

# 2.2 - Signal: Limpar ru√≠do
from src.preprocessing.signal_processing import clean_signal
clean_speed = clean_signal(synchronized['Speed'], method="median")

# 2.3 - Stats: Calcular features
from src.preprocessing.feature_engineering import enrich_dataframe_with_stats
enriched = enrich_dataframe_with_stats(
    laps_df,
    group_by=['Stint', 'Compound']
)

# 3. Sa√≠da: DataFrame "Enriched" e limpo

# 4. Pr√≥ximos passos:
# - Ruptures: detectar pontos de mudan√ßa
# - Scikit-learn: clustering por estrat√©gia
```

## üìä Quando Usar Cada M√≥dulo

| M√≥dulo | Quando Usar |
|--------|-------------|
| **interpolation** | Comparar pilotos, calcular deltas, criar matriz de voltas |
| **signal_processing** | Remover ru√≠do de sensores, calcular acelera√ß√£o/derivadas |
| **feature_engineering** | Detectar outliers, calcular degrada√ß√£o, preparar para ML |

## üß™ Testes

Todos os m√≥dulos possuem testes unit√°rios completos:

```bash
# Rodar todos os testes
uv run pytest tests/preprocessing/ -v

# Rodar testes de um m√≥dulo espec√≠fico
uv run pytest tests/preprocessing/test_interpolation.py -v
uv run pytest tests/preprocessing/test_signal_processing.py -v
uv run pytest tests/preprocessing/test_feature_engineering.py -v
```

## üìñ Exemplos Pr√°ticos

Veja `examples/preprocessing_example.py` para exemplos completos de:
1. Sincroniza√ß√£o de telemetria para compara√ß√£o de pilotos
2. Processamento de sinal e c√°lculo de derivadas
3. Engenharia de features para an√°lise de stint
4. Pipeline completo para ML

```bash
# Rodar exemplos
uv run python examples/preprocessing_example.py
```

## üîó Integra√ß√£o com Outras Camadas

```
FastF1 (extra√ß√£o)
    ‚Üì
SciPy (pr√©-processamento)
    ‚Üì
‚îú‚îÄ‚Üí Scikit-learn (clustering, anomalias)
‚îú‚îÄ‚Üí Ruptures (pontos de mudan√ßa)
‚îî‚îÄ‚Üí Pydantic (valida√ß√£o de features)
```

## üìö Refer√™ncias

- Documenta√ß√£o SciPy Interpolate: https://docs.scipy.org/doc/scipy/reference/interpolate.html
- Documenta√ß√£o SciPy Signal: https://docs.scipy.org/doc/scipy/reference/signal.html
- Documenta√ß√£o SciPy Stats: https://docs.scipy.org/doc/scipy/reference/stats.html
