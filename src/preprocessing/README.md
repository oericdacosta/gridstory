# Preprocessing Module - SciPy Layer

MÃ³dulo de prÃ©-processamento matemÃ¡tico de dados de telemetria F1 usando **SciPy**. Este mÃ³dulo transforma dados brutos e dessincronizados do FastF1 em sinais matemÃ¡ticos limpos e comparÃ¡veis para anÃ¡lise de Machine Learning.

## ğŸ¯ Objetivo

O SciPy atua como **motor matemÃ¡tico de prÃ©-processamento e engenharia de features**, preparando dados para:
- **Scikit-learn**: modelos de clustering e detecÃ§Ã£o de anomalias
- **Ruptures**: detecÃ§Ã£o de pontos de mudanÃ§a (degradaÃ§Ã£o de pneus)

## ğŸ“¦ Componentes

### 1. SincronizaÃ§Ã£o de Telemetria (`interpolation.py`)

**Problema**: Dados de telemetria chegam dessincronizados - diferentes pilotos tÃªm mediÃ§Ãµes em pontos diferentes da pista.

**SoluÃ§Ã£o**: InterpolaÃ§Ã£o cÃºbica spline para criar um grid comum de distÃ¢ncia.

**Ferramentas**:
- `scipy.interpolate.make_interp_spline`
- `scipy.interpolate.CubicSpline`

**FunÃ§Ãµes**:
```python
synchronize_telemetry(
    telemetry: pd.DataFrame,
    track_length: float,
    num_points: int = 5000,
) -> pd.DataFrame
```

**Exemplo**:
```python
from src.preprocessing.interpolation import synchronize_telemetry

# Sincronizar telemetria de um piloto
ver_telemetry = lap.get_telemetry()
synchronized = synchronize_telemetry(
    ver_telemetry,
    track_length=5281.0,  # Monaco
    num_points=5000
)

# Agora pode comparar diretamente com outros pilotos
ham_synchronized = synchronize_telemetry(ham_telemetry, 5281.0, 5000)
speed_delta = synchronized['Speed'] - ham_synchronized['Speed']
```

**Resultado**:
- Matriz onde cada linha = uma volta
- Cada coluna = um ponto exato da pista
- Pronta para comparaÃ§Ãµes diretas e cÃ¡lculos de delta

---

### 2. Tratamento de Sinal (`signal_processing.py`)

**Problema**: Sensores tÃªm ruÃ­do - picos repentinos que nÃ£o representam aÃ§Ãµes reais do piloto.

**SoluÃ§Ã£o**: Filtros de processamento de sinais para suavizar curvas preservando informaÃ§Ã£o importante.

**Ferramentas**:
- `scipy.signal.medfilt` - Remove outliers pontuais preservando bordas
- `scipy.signal.savgol_filter` - SuavizaÃ§Ã£o e cÃ¡lculo de derivadas

**FunÃ§Ãµes**:
```python
clean_signal(
    signal: np.ndarray,
    method: str = "median",  # ou "savgol"
    kernel_size: int = 5,
) -> np.ndarray

calculate_derivative(
    signal: np.ndarray,
    delta_x: float = 1.0,
    smooth: bool = True,
) -> np.ndarray

apply_telemetry_pipeline(
    telemetry_dict: dict[str, np.ndarray],
    noise_reduction: bool = True,
    outlier_removal: bool = True,
    calculate_derivatives: bool = False,
) -> dict[str, np.ndarray]
```

**Exemplo**:
```python
from src.preprocessing.signal_processing import apply_telemetry_pipeline

telemetry = {
    'Speed': speed_array,
    'Throttle': throttle_array,
    'Brake': brake_array,
}

# Pipeline completo
processed = apply_telemetry_pipeline(
    telemetry,
    noise_reduction=True,      # Remove ruÃ­do
    outlier_removal=True,       # Remove spikes
    calculate_derivatives=True, # Calcula aceleraÃ§Ã£o
)

# Resultado inclui:
# - 'Speed', 'Throttle', 'Brake' (limpos)
# - 'Speed_derivative' (aceleraÃ§Ã£o)
# - 'Throttle_derivative', 'Brake_derivative'
```

**Resultado**:
- Dados "polidos" onde variaÃ§Ãµes representam apenas fÃ­sica do carro
- Facilita detecÃ§Ã£o de anomalias reais pelo Isolation Forest

---

### 3. Engenharia de Features EstatÃ­sticas (`feature_engineering.py`)

**Problema**: Identificar outliers simples antes de usar IA complexa (ex: volta lenta por trÃ¡fego).

**SoluÃ§Ã£o**: EstatÃ­stica clÃ¡ssica para filtrar o Ã³bvio e criar features descritivas.

**Ferramentas**:
- `scipy.stats.zscore` - NormalizaÃ§Ã£o e detecÃ§Ã£o de outliers
- `scipy.stats.describe` - EstatÃ­sticas descritivas
- `scipy.stats.linregress` - Taxa de degradaÃ§Ã£o

**FunÃ§Ãµes**:
```python
calculate_statistical_features(
    df: pd.DataFrame,
    value_column: str = 'LapTime',
    group_by: list[str] | None = None,
) -> pd.DataFrame

calculate_degradation_rate(
    df: pd.DataFrame,
    lap_column: str = 'LapNumber',
    time_column: str = 'LapTime',
    group_by: list[str] | None = None,
) -> pd.DataFrame

enrich_dataframe_with_stats(
    df: pd.DataFrame,
    value_column: str = 'LapTime',
    group_by: list[str] | None = None,
    include_degradation: bool = True,
) -> pd.DataFrame
```

**Exemplo**:
```python
from src.preprocessing.feature_engineering import enrich_dataframe_with_stats

# DataFrame com tempos de volta
laps_df = session.laps[['LapNumber', 'LapTime', 'Driver', 'Compound']]

# Adicionar features estatÃ­sticas
enriched = enrich_dataframe_with_stats(
    laps_df,
    value_column='LapTime',
    group_by=['Driver', 'Compound'],
    include_degradation=True
)

# Colunas adicionadas:
# - z_score: score normalizado
# - is_outlier: flag para |z| > 3
# - group_mean, group_std: estatÃ­sticas do grupo
# - degradation_slope: taxa de degradaÃ§Ã£o (s/lap)
# - degradation_r_squared: qualidade do fit
# - degradation_intercept: tempo estimado primeira volta

# Filtrar outliers
clean_laps = enriched[~enriched['is_outlier']]

# Analisar degradaÃ§Ã£o
for driver in enriched['Driver'].unique():
    driver_data = enriched[enriched['Driver'] == driver].iloc[0]
    print(f"{driver}: {driver_data['degradation_slope']:.3f}s/lap")
```

**Resultado**:
- DataFrame com flags de outliers
- Features de degradaÃ§Ã£o para Pydantic
- Entrada limpa para Scikit-learn

---

## ğŸ”„ Fluxo Completo

```python
# 1. Entrada: Dados brutos do FastF1
session = fastf1.get_session(2024, 'Monaco', 'R')
session.load()
laps = session.laps.pick_driver('VER')

# 2. Processamento SciPy

# 2.1 - InterpolaÃ§Ã£o: Sincronizar telemetria
from src.preprocessing.interpolation import synchronize_telemetry
synchronized = synchronize_telemetry(
    telemetry,
    track_length=session.get_circuit_info().total_distance
)

# 2.2 - Signal: Limpar ruÃ­do
from src.preprocessing.signal_processing import clean_signal
clean_speed = clean_signal(synchronized['Speed'], method="median")

# 2.3 - Stats: Calcular features
from src.preprocessing.feature_engineering import enrich_dataframe_with_stats
enriched = enrich_dataframe_with_stats(
    laps_df,
    group_by=['Stint', 'Compound']
)

# 3. SaÃ­da: DataFrame "Enriched" e limpo

# 4. PrÃ³ximos passos:
# - Ruptures: detectar pontos de mudanÃ§a
# - Scikit-learn: clustering por estratÃ©gia
```

## ğŸ“Š Quando Usar Cada MÃ³dulo

| MÃ³dulo | Quando Usar |
|--------|-------------|
| **interpolation** | Comparar pilotos, calcular deltas, criar matriz de voltas |
| **signal_processing** | Remover ruÃ­do de sensores, calcular aceleraÃ§Ã£o/derivadas |
| **feature_engineering** | Detectar outliers, calcular degradaÃ§Ã£o, preparar para ML |

## ğŸ§ª Testes

Todos os mÃ³dulos possuem testes unitÃ¡rios completos:

```bash
# Rodar todos os testes
uv run pytest tests/preprocessing/ -v

# Rodar testes de um mÃ³dulo especÃ­fico
uv run pytest tests/preprocessing/test_interpolation.py -v
uv run pytest tests/preprocessing/test_signal_processing.py -v
uv run pytest tests/preprocessing/test_feature_engineering.py -v
```

## ğŸ“– Exemplos PrÃ¡ticos

Veja `examples/preprocessing_example.py` para exemplos completos de:
1. SincronizaÃ§Ã£o de telemetria para comparaÃ§Ã£o de pilotos
2. Processamento de sinal e cÃ¡lculo de derivadas
3. Engenharia de features para anÃ¡lise de stint
4. Pipeline completo para ML

```bash
# Rodar exemplos
uv run python examples/preprocessing_example.py
```

## ğŸ”— IntegraÃ§Ã£o com Outras Camadas

```
FastF1 (extraÃ§Ã£o)
    â†“
SciPy (prÃ©-processamento)
    â†“
â”œâ”€â†’ Scikit-learn (clustering, anomalias)
â”œâ”€â†’ Ruptures (pontos de mudanÃ§a)
â””â”€â†’ Pydantic (validaÃ§Ã£o de features)
```

## ğŸ“š ReferÃªncias

- DocumentaÃ§Ã£o SciPy Interpolate: https://docs.scipy.org/doc/scipy/reference/interpolate.html
- DocumentaÃ§Ã£o SciPy Signal: https://docs.scipy.org/doc/scipy/reference/signal.html
- DocumentaÃ§Ã£o SciPy Stats: https://docs.scipy.org/doc/scipy/reference/stats.html
