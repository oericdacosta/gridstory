# gridstory

> F1 race data pipeline â€” from raw telemetry to structured JSON events ready for LLM-powered narrative generation.

![Python](https://img.shields.io/badge/python-3.12%2B-blue)
![uv](https://img.shields.io/badge/package%20manager-uv-violet)
![Status](https://img.shields.io/badge/status-active%20development-orange)

gridstory is a two-module system for Formula 1 race analysis:

- **Module 1 (complete):** Data engineering + ML pipeline that processes a race and outputs three validated JSON files
- **Module 2 (planned):** LLM layer that turns those JSONs into a journalistic report and an interactive chatbot

```
FastF1 API â†’ Extract â†’ Preprocess â†’ ML â†’ Pydantic â†’ timeline.json
                                                    â†’ race_summary.json
                                                    â†’ driver_profiles.json
                                                          â†“
                                               DSPY â†’ race_report.md
                                               Agno â†’ chat endpoint
                                             FastAPI â†’ REST API
```

---

## Features

**Module 1 â€” implemented**

- Extracts all race data via FastF1: laps, telemetry, race control, weather, results
- Detects tire degradation cliffs with Ruptures/PELT change point detection
- Classifies lap clusters (push / base / degraded) with K-Means
- Identifies anomalous laps with Isolation Forest, cross-referenced with Safety Car events
- Detects undercut maneuvers from pit timing and position data
- Outputs three Pydantic-validated JSONs â€” the only interface between ML and LLM:
  - `timeline.json` â€” chronological race events (safety car, driver error, tire dropoff, undercut, penalty)
  - `race_summary.json` â€” winner, podium, DNFs, safety car count, weather
  - `driver_profiles.json` â€” per-driver: compounds, push/base/degraded %, tire cliffs, anomalies
- MLflow tracking for all ML experiments (config-driven)

**Module 2 â€” planned**

- DSPY journalistic report generation from the three JSONs
- Agno knowledge base chatbot ("Who executed the best undercut?")
- FastAPI endpoints: `GET /race/{year}/{round}/report` and `POST /race/{year}/{round}/chat`

---

## Quick Start

```bash
# Clone and install
git clone https://github.com/seu-usuario/gridstory.git
cd gridstory
uv sync

# Run the full pipeline for 2025 Round 1 (Australian GP)
uv run python cli/pipeline.py 2025 1
```

Output:

```
data/
â”œâ”€â”€ raw/races/2025/round_01/          # Phase 1: raw Parquet files
â”œâ”€â”€ processed/races/2025/round_01/    # Phase 2: engineered features
â”œâ”€â”€ ml/races/2025/round_01/           # Phase 3: ML outputs
â””â”€â”€ timelines/races/2025/round_01/    # Phase 4: Pydantic-validated JSONs
    â”œâ”€â”€ timeline.json
    â”œâ”€â”€ race_summary.json
    â””â”€â”€ driver_profiles.json
```

---

## Installation

**Requirements:** Python 3.12+, [uv](https://github.com/astral-sh/uv)

```bash
git clone https://github.com/seu-usuario/gridstory.git
cd gridstory
uv sync
```

---

## Usage

### Pipeline (single command)

```bash
# Full pipeline â€” extract, preprocess, ML, generate JSONs
uv run python cli/pipeline.py 2025 1

# Use polling for very recent races (data may not be available yet)
uv run python cli/pipeline.py 2025 1 --polling

# Print data samples at each phase
uv run python cli/pipeline.py 2025 1 --show-sample
```

### MLflow UI

```bash
# View experiment tracking (clustering metrics, anomaly rates, PELT penalty runs)
uv run mlflow ui
# http://localhost:5000
```

### PELT penalty calibration

```bash
# Run penalty search and compare in MLflow UI
uv run python cli/ruptures_analysis.py --year 2025 --round 1 --penalty-search --mlflow

# After choosing the best value, set ml.degradation.penalty in config.yaml
```

---

## Output JSONs

The three files in `data/timelines/races/YEAR/round_XX/` are the single source of truth for Module 2.

### `timeline.json`

Chronological list of significant race events. Every field is narrative-ready â€” no internal ML metrics.

```json
[
  { "lap": 1,  "type": "safety_car",       "deployed_on_lap": 1, "duration_laps": 6 },
  { "lap": 37, "type": "driver_error",     "driver": "LEC" },
  { "lap": 38, "type": "tire_dropoff",     "driver": "ALB", "lap_time_drop_seconds": 1.39, "cliff_validated": true },
  { "lap": 43, "type": "penalty",          "driver": "BOR", "reason": "Unsafe Release" },
  { "lap": 47, "type": "undercut",         "winner": "NOR", "loser": "VER", "time_gained_seconds": 0.803 }
]
```

Event types: `safety_car` Â· `driver_error` Â· `external_incident` Â· `tire_dropoff` Â· `undercut` Â· `penalty`

### `race_summary.json`

```json
{
  "year": 2025, "round": 1, "total_laps": 57,
  "winner": "NOR", "fastest_lap_driver": "NOR", "fastest_lap_time": 82.167,
  "podium": [{ "position": 1, "driver": "NOR", "team": "McLaren", "gap_to_leader": "0.000" }],
  "dnfs": [{ "driver": "LAW", "on_lap": 47 }],
  "safety_car_count": 3,
  "weather": { "condition": "mixed", "air_temp_avg_c": 15.7, "had_rainfall": true }
}
```

### `driver_profiles.json`

```json
[
  {
    "driver": "NOR", "team": "McLaren",
    "final_position": 1, "grid_position": 1, "positions_gained": 0, "points": 25.0,
    "push_pct": 0.067, "base_pct": 0.844, "degraded_pct": 0.089,
    "compounds_used": [{ "compound": "INTERMEDIATE", "laps": 47 }, { "compound": "HARD", "laps": 10 }],
    "had_tire_cliff": true, "cliff_count": 1, "anomaly_count": 3
  }
]
```

---

## Architecture

```
gridstory/
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ pipeline.py                  # Single entry point
â”‚   â”œâ”€â”€ pipeline_steps/
â”‚   â”‚   â”œâ”€â”€ extraction.py            # Phase 1
â”‚   â”‚   â”œâ”€â”€ preprocessing.py         # Phase 2
â”‚   â”‚   â”œâ”€â”€ ml.py                    # Phase 3
â”‚   â”‚   â”œâ”€â”€ events.py                # Phase 4 â€” generates the 3 JSONs
â”‚   â”‚   â””â”€â”€ reporting.py
â”‚   â”œâ”€â”€ ruptures_analysis.py         # PELT penalty calibration tool
â”‚   â””â”€â”€ list_data.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extraction/                  # FastF1 ETL
â”‚   â”œâ”€â”€ preprocessing/               # SciPy signal processing + feature engineering
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ pipeline.py              # run_race_analysis()
â”‚   â”‚   â”œâ”€â”€ clustering.py            # K-Means, DBSCAN
â”‚   â”‚   â”œâ”€â”€ anomaly_detection.py     # Isolation Forest
â”‚   â”‚   â”œâ”€â”€ anomaly_classification.py# Z-score + race control cross-reference
â”‚   â”‚   â”œâ”€â”€ change_point.py          # Ruptures/PELT tire cliffs
â”‚   â”‚   â”œâ”€â”€ strategy.py              # detect_undercuts()
â”‚   â”‚   â”œâ”€â”€ timeline.py              # build_race_timeline()
â”‚   â”‚   â”œâ”€â”€ race_summary_builder.py  # build_race_summary()
â”‚   â”‚   â”œâ”€â”€ driver_profiles_builder.py # build_driver_profiles()
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ tracking.py              # MLflow integration
â”‚   â”œâ”€â”€ models/                      # Pydantic contracts (ML â†” LLM firewall)
â”‚   â”‚   â”œâ”€â”€ race_events.py           # RaceTimeline + all event types
â”‚   â”‚   â”œâ”€â”€ race_summary.py          # RaceSummary, WeatherSummary, PodiumEntry
â”‚   â”‚   â””â”€â”€ driver_profile.py        # DriverProfile, CompoundUsage
â”‚   â”œâ”€â”€ llm/                         # [planned] DSPY + Agno
â”‚   â”œâ”€â”€ api/                         # [planned] FastAPI
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ data/                            # gitignored
â”‚   â”œâ”€â”€ raw/races/
â”‚   â”œâ”€â”€ processed/races/
â”‚   â”œâ”€â”€ ml/races/
â”‚   â””â”€â”€ timelines/races/
â”‚
â”œâ”€â”€ config.yaml                      # All pipeline parameters
â””â”€â”€ pyproject.toml
```

---

## Tech Stack

| Layer | Tools | Status |
|---|---|---|
| Data extraction | FastF1, Pandas, NumPy | âœ… Done |
| Storage | Parquet (PyArrow) | âœ… Done |
| Preprocessing | SciPy (interpolate, signal, stats) | âœ… Done |
| ML â€” clustering | Scikit-learn K-Means, DBSCAN | âœ… Done |
| ML â€” anomaly detection | Scikit-learn Isolation Forest | âœ… Done |
| ML â€” change point | Ruptures/PELT | âœ… Done |
| ML tracking | MLflow | âœ… Done |
| Data contracts | Pydantic v2 | âœ… Done |
| Report generation | DSPY | ðŸ“… Planned |
| Chatbot | Agno | ðŸ“… Planned |
| API | FastAPI | ðŸ“… Planned |

---

## Configuration

All pipeline parameters live in `config.yaml`:

```yaml
mlflow:
  enabled: true          # set to false to skip tracking

ml:
  degradation:
    penalty: 3           # PELT sensitivity â€” calibrate with ruptures_analysis.py
    min_cliff_magnitude: 0.3
```

See [docs/configuration.md](docs/configuration.md) for all options.

---

## Project Status

| Phase | Description | Status |
|---|---|---|
| 1 â€” Extraction | FastF1 â†’ Parquet | âœ… Complete |
| 2 â€” Preprocessing | SciPy feature engineering | âœ… Complete |
| 3 â€” Machine Learning | Clustering, anomaly detection, tire cliffs | âœ… Complete |
| 4 â€” Pydantic contracts | Validate ML outputs â†’ 3 JSONs | âœ… Complete |
| 5 â€” LLM report | DSPY journalistic report | ðŸ“… Next |
| 6 â€” LLM chatbot | Agno knowledge base Q&A | ðŸ“… Next |
| 7 â€” API | FastAPI endpoints | ðŸ“… Next |

---

## Documentation

- [USAGE.md](USAGE.md) â€” detailed usage guide
- [ARCHITECTURE.md](ARCHITECTURE.md) â€” architecture and data flow
- [CHANGELOG.md](CHANGELOG.md) â€” version history
- [cli/README.md](cli/README.md) â€” CLI reference
- [src/ml/README.md](src/ml/README.md) â€” ML module reference
- [docs/configuration.md](docs/configuration.md) â€” config.yaml reference

---

## Contributing

Issues and pull requests are welcome.
