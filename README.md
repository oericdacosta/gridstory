# PitWall AI

**Pipeline completo de anÃ¡lise de corridas de FÃ³rmula 1 usando FastF1, NumPy, Pandas e SciPy.**

## Sobre o Projeto

PitWall AI Ã© um pipeline de engenharia de dados para anÃ¡lise de corridas de FÃ³rmula 1 que:

1. **Extrai TODOS os dados** de uma corrida usando FastF1
2. **PrÃ©-processa TUDO** com NumPy, Pandas e SciPy
3. **Prepara dados estruturados** prontos para anÃ¡lise ML

**Pipeline atual (implementado):**
- âœ… ExtraÃ§Ã£o completa de dados (laps, telemetry, race_control, weather, results)
- âœ… PrÃ©-processamento com SciPy (interpolaÃ§Ã£o, signal processing, features estatÃ­sticas)
- âœ… Machine Learning com Scikit-learn (clustering, anomaly detection, pipeline)
- ğŸš§ ExportaÃ§Ã£o estruturada (prÃ³xima fase: Pydantic)
- ğŸš§ GeraÃ§Ã£o de narrativas com LLM (fase futura: DSPY, Agno, FastAPI)

## Status do Desenvolvimento

| MÃ³dulo | Status | DescriÃ§Ã£o |
|--------|--------|-----------|
| ExtraÃ§Ã£o de Dados | âœ… Implementado | FastF1, Pandas, NumPy |
| PrÃ©-processamento | âœ… Implementado | SciPy (interpolaÃ§Ã£o, signal processing, features) + Scikit-learn (imputaÃ§Ã£o, encoding, escalonamento) |
| Machine Learning | âœ… Implementado | Scikit-learn (K-Means, DBSCAN, Isolation Forest, Pipeline) |
| ValidaÃ§Ã£o | Planejado | Pydantic |
| API | Planejado | FastAPI |
| LLM | Planejado | DSPY, Agno |
| Observabilidade | Planejado | MLflow |

## InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) (gerenciador de pacotes)

### Setup

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/pitwall-ai.git
cd pitwall-ai

# Instale as dependÃªncias
uv sync
```

## Uso RÃ¡pido

### Pipeline Completo (ExtraÃ§Ã£o + PrÃ©-processamento)

```bash
# Um Ãºnico comando que faz TUDO
uv run python cli/pipeline.py 2025 1

# Com polling (aguardar disponibilidade dos dados)
uv run python cli/pipeline.py 2025 1 --polling

# Mostrar amostras dos dados processados
uv run python cli/pipeline.py 2025 1 --show-sample
```

**O que este comando faz:**
1. âœ… Extrai TODOS os dados da corrida (laps, telemetry, race_control, weather, results)
2. âœ… PrÃ©-processa TODOS os dados (features, normalizaÃ§Ã£o, limpeza)
3. âœ… Executa ML (clustering K-Means, detecÃ§Ã£o de anomalias Isolation Forest)
4. âœ… Salva dados brutos em `data/raw/races/YEAR/round_XX/`
5. âœ… Salva dados processados em `data/processed/races/YEAR/round_XX/`
6. âœ… Salva resultados de ML em `data/ml/races/YEAR/round_XX/`

### Comandos Individuais (Opcional)

```bash
# Apenas extraÃ§Ã£o (SEMPRE extrai todos os dados)
uv run python cli/extract.py 2025 1

# Apenas prÃ©-processamento (de dados jÃ¡ extraÃ­dos)
uv run python cli/preprocess.py --year 2025 --round 1 --all --save
```

### DocumentaÃ§Ã£o Completa

- [USAGE.md](USAGE.md) - Guia de uso do pipeline completo
- [PREPROCESSING.md](PREPROCESSING.md) - Guia completo de prÃ©-processamento (todos os dados)
- [docs/configuration.md](docs/configuration.md) - **Guia de configuraÃ§Ã£o** (config.yaml)
- [src/extraction/README.md](src/extraction/README.md) - DocumentaÃ§Ã£o do mÃ³dulo de extraÃ§Ã£o
- [src/preprocessing/README.md](src/preprocessing/README.md) - DocumentaÃ§Ã£o do mÃ³dulo de prÃ©-processamento
- [src/ml/README.md](src/ml/README.md) - DocumentaÃ§Ã£o do mÃ³dulo de Machine Learning (Scikit-learn)
- [cli/README.md](cli/README.md) - DocumentaÃ§Ã£o dos CLIs

## Estrutura do Projeto

```
pitwall-ai/
â”œâ”€â”€ cli/                           # Scripts de linha de comando
â”‚   â”œâ”€â”€ pipeline.py                # Pipeline completo (orquestrador)
â”‚   â”œâ”€â”€ pipeline_steps/            # MÃ³dulos do pipeline
â”‚   â”‚   â”œâ”€â”€ extraction.py          # Fase 1: ExtraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # Fase 2: PrÃ©-processamento
â”‚   â”‚   â”œâ”€â”€ ml.py                  # Fase 3: Machine Learning
â”‚   â”‚   â””â”€â”€ reporting.py           # FormataÃ§Ã£o de saÃ­das
â”‚   â”œâ”€â”€ extract.py                 # CLI de extraÃ§Ã£o individual
â”‚   â””â”€â”€ preprocess.py              # CLI de prÃ©-processamento individual
â”œâ”€â”€ src/                           # CÃ³digo-fonte
â”‚   â”œâ”€â”€ extraction/                # ExtraÃ§Ã£o de dados (âœ… implementado)
â”‚   â”œâ”€â”€ preprocessing/             # PrÃ©-processamento (âœ… implementado)
â”‚   â”‚   â”œâ”€â”€ interpolation.py       # SincronizaÃ§Ã£o de telemetria
â”‚   â”‚   â”œâ”€â”€ signal_processing.py   # Tratamento de sinal
â”‚   â”‚   â””â”€â”€ feature_engineering/   # Engenharia de features (modular)
â”‚   â”‚       â”œâ”€â”€ statistical.py     # Features estatÃ­sticas
â”‚   â”‚       â”œâ”€â”€ domain.py          # PrÃ©-processamento F1
â”‚   â”‚       â””â”€â”€ ml_prep.py         # PreparaÃ§Ã£o para ML
â”‚   â”œâ”€â”€ ml/                        # Machine Learning (âœ… implementado)
â”‚   â”œâ”€â”€ models/                    # Modelos Pydantic (planejado)
â”‚   â”œâ”€â”€ api/                       # FastAPI (planejado)
â”‚   â”œâ”€â”€ llm/                       # IntegraÃ§Ã£o LLM (planejado)
â”‚   â””â”€â”€ utils/                     # UtilitÃ¡rios e configuraÃ§Ã£o
â”œâ”€â”€ tests/                         # Testes automatizados
â”œâ”€â”€ examples/                      # Exemplos de uso
â”œâ”€â”€ data/                          # Dados (nÃ£o versionado)
â”‚   â”œâ”€â”€ raw/races/                 # Dados brutos extraÃ­dos
â”‚   â”œâ”€â”€ processed/races/           # Dados prÃ©-processados
â”‚   â””â”€â”€ ml/races/                  # Resultados de Machine Learning
â”œâ”€â”€ docs/                          # DocumentaÃ§Ã£o
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”œâ”€â”€ config.yaml                    # âš™ï¸ ConfiguraÃ§Ã£o centralizada
â””â”€â”€ main.py                        # Entry point (futuro: servidor API)
```

### ConfiguraÃ§Ã£o Centralizada

Todos os parÃ¢metros do pipeline estÃ£o centralizados em `config.yaml`:
- **PrÃ©-processamento**: num_points, kernel_size, thresholds, etc.
- **Machine Learning**: random_state, contamination, k_range, etc.
- **DiretÃ³rios**: Estrutura de dados configurÃ¡vel

Edite `config.yaml` para customizar o comportamento do pipeline sem modificar cÃ³digo.

### Estrutura de Dados Gerada

```
data/
â”œâ”€â”€ raw/races/YEAR/round_XX/              # FASE 1: ExtraÃ§Ã£o
â”‚   â”œâ”€â”€ laps.parquet
â”‚   â”œâ”€â”€ telemetry/*.parquet
â”‚   â”œâ”€â”€ race_control.parquet
â”‚   â”œâ”€â”€ weather.parquet
â”‚   â”œâ”€â”€ results.parquet
â”‚   â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ processed/races/YEAR/round_XX/        # FASE 2: PrÃ©-processamento
â”‚   â”œâ”€â”€ laps_processed.parquet
â”‚   â”œâ”€â”€ telemetry/*_processed.parquet
â”‚   â”œâ”€â”€ race_control_processed.parquet
â”‚   â”œâ”€â”€ weather_processed.parquet
â”‚   â””â”€â”€ results_processed.parquet
â”‚
â””â”€â”€ ml/races/YEAR/round_XX/               # FASE 3: Machine Learning
    â”œâ”€â”€ laps_clustered.parquet            # Clustering (ritmos)
    â”œâ”€â”€ laps_anomalies.parquet            # DetecÃ§Ã£o de anomalias
    â””â”€â”€ anomalies_summary.parquet         # SumÃ¡rio por piloto
```

## Funcionalidades

### 1. ExtraÃ§Ã£o Completa de Dados (âœ… Implementado)

**SEMPRE extrai TODOS os dados de uma corrida:**

- **Laps**: Tempos por setor, pit stops, compostos de pneu, desgaste de pneu
- **Telemetria**: Velocidade, RPM, aceleraÃ§Ã£o, freio, DRS, marchas (TODOS os pilotos)
- **Race Control**: Safety Car, bandeiras, penalidades, investigaÃ§Ãµes
- **Weather**: Temperatura do ar/pista, chuva, vento, pressÃ£o, umidade
- **Results**: ClassificaÃ§Ã£o final, grid de largada, pontos, status

**Formato:** Parquet (eficiente e compacto)
**OrganizaÃ§Ã£o:** `data/raw/races/YEAR/round_XX/`

### 2. PrÃ©-processamento Completo (âœ… Implementado)

**Transforma TODOS os dados brutos em features prontas para anÃ¡lise:**

#### **A. Laps (Voltas e EstratÃ©gia)**
- Features estatÃ­sticas (Z-score, outliers)
- Taxa de degradaÃ§Ã£o de pneus (regressÃ£o linear)
- EstatÃ­sticas descritivas por grupo (piloto, composto)

#### **B. Telemetria (Dados do Carro)**
- SincronizaÃ§Ã£o em grid comum (`scipy.interpolate`)
- RemoÃ§Ã£o de ruÃ­do (`scipy.signal`)
- CÃ¡lculo de derivadas (aceleraÃ§Ã£o, jerk)
- DetecÃ§Ã£o e correÃ§Ã£o de outliers

#### **C. Race Control (Eventos da Corrida)**
- NormalizaÃ§Ã£o de timestamps
- Indicadores binÃ¡rios (safety car, bandeiras, penalidades)
- CategorizaÃ§Ã£o de eventos
- Severidade do evento (info/warning/critical)

#### **D. Weather (CondiÃ§Ãµes MeteorolÃ³gicas)**
- InterpolaÃ§Ã£o de valores faltantes
- NormalizaÃ§Ã£o de temperaturas
- TendÃªncias climÃ¡ticas (temperatura subindo/descendo)
- DetecÃ§Ã£o de mudanÃ§as bruscas

#### **E. Results (ClassificaÃ§Ã£o Final)**
- MudanÃ§a de posiÃ§Ãµes (grid â†’ final)
- Status de finalizaÃ§Ã£o (finished/DNF)
- CategorizaÃ§Ã£o de DNF (collision/mechanical/electrical)
- Score de desempenho relativo

#### **F. PrÃ©-processamento para Scikit-learn**
- **ImputaÃ§Ã£o**: Preenche valores faltantes (SimpleImputer, KNNImputer)
- **Encoding**: Converte categorias em nÃºmeros (OneHotEncoder para Compound, TrackStatus)
- **Escalonamento**: Normaliza features (StandardScaler, RobustScaler)

**Por quÃª:** Algoritmos de ML baseados em distÃ¢ncia (K-Means, DBSCAN, Isolation Forest) requerem dados completos, numÃ©ricos e na mesma escala.

**Formato:** Parquet processado
**OrganizaÃ§Ã£o:** `data/processed/races/YEAR/round_XX/`

### 3. Machine Learning com Scikit-learn (âœ… Implementado)

**AnÃ¡lise nÃ£o supervisionada para identificar padrÃµes e eventos:**

#### **A. ClusterizaÃ§Ã£o (AnÃ¡lise de Ritmo)**
- **K-Means**: Agrupa voltas em ritmos (Puro, GestÃ£o de Pneus, TrÃ¡fego)
- **DBSCAN**: Identifica ritmo consistente e detecta ruÃ­do automaticamente
- **AplicaÃ§Ãµes**: Identificar mudanÃ§as de estratÃ©gia, filtrar trÃ¡fego

#### **B. DetecÃ§Ã£o de Anomalias**
- **Isolation Forest**: Detecta eventos raros e outliers
- **AplicaÃ§Ãµes**: Erros de piloto, quebras mecÃ¢nicas, voltas excepcionais
- **SaÃ­da**: Flags binÃ¡rios + scores de anomalia

#### **C. Pipeline Integrado**
- **ColumnTransformer**: PrÃ©-processamento em um objeto Ãºnico
- **Pipeline Scikit-learn**: Encapsula prÃ©-proc + ML
- **run_race_analysis()**: FunÃ§Ã£o de alto nÃ­vel para anÃ¡lise completa

**Formato:** DataFrames com labels e scores
**DocumentaÃ§Ã£o:** [src/ml/README.md](src/ml/README.md)

## Arquitetura

O projeto Ã© um **pipeline de engenharia de dados** com fases bem definidas:

### **FASE 1: ExtraÃ§Ã£o (âœ… Implementado)**
```
FastF1 API â†’ ExtraÃ§Ã£o Completa â†’ Parquet (data/raw/)
```
- Laps, Telemetry, Race Control, Weather, Results
- Cache local do FastF1 para eficiÃªncia
- OrganizaÃ§Ã£o hierÃ¡rquica por temporada/rodada

### **FASE 2: PrÃ©-processamento (âœ… Implementado)**
```
Dados Brutos â†’ NumPy/Pandas/SciPy/Scikit-learn â†’ Parquet (data/processed/)
```
- **Laps:** Features estatÃ­sticas, degradaÃ§Ã£o de pneus
- **Telemetria:** SincronizaÃ§Ã£o, limpeza, derivadas
- **Race Control:** Eventos estruturados, severidade
- **Weather:** TendÃªncias, mudanÃ§as bruscas
- **Results:** Desempenho relativo, classificaÃ§Ã£o
- **Para ML:** ImputaÃ§Ã£o, Encoding, Escalonamento

### **FASE 3: Machine Learning (âœ… Implementado)**
```
Dados Processados â†’ Scikit-learn â†’ DataFrames com Labels/Scores
```
- **K-Means**: Agrupamento de voltas por ritmo
- **DBSCAN**: DetecÃ§Ã£o de clusters + ruÃ­do
- **Isolation Forest**: DetecÃ§Ã£o de anomalias (eventos raros)
- **Pipeline**: IntegraÃ§Ã£o prÃ©-processamento + ML

### **FASE 4: ExportaÃ§Ã£o Estruturada (ğŸš§ PrÃ³xima Fase)**
```
DataFrames â†’ Pydantic â†’ JSON Estruturado
```
- Pydantic: ValidaÃ§Ã£o e estruturaÃ§Ã£o de eventos
- Schema de eventos (clusters, anomalias, mudanÃ§as de ritmo)
- ExportaÃ§Ã£o para consumo downstream

### **FASE 5: LLM & API (ğŸš§ Planejado)**
```
Eventos (JSON) â†’ DSPY/Agno â†’ Narrativas & Chat
```
- DSPY: GeraÃ§Ã£o de relatÃ³rios narrativos
- Agno: Chatbot interativo com contexto
- FastAPI: API REST para consultas
- MLflow: Observabilidade e tracing

## Stack TecnolÃ³gica

| Camada | Tecnologia | Status | DocumentaÃ§Ã£o |
|--------|-----------|--------|--------------|
| ExtraÃ§Ã£o | FastF1, Pandas, NumPy | âœ… Implementado | [src/extraction/](src/extraction/README.md) |
| Armazenamento | Parquet (PyArrow) | âœ… Implementado | - |
| PrÃ©-processamento | SciPy (interpolate, signal, stats) | âœ… Implementado | [src/preprocessing/](src/preprocessing/README.md) |
| PrÃ©-proc ML | Scikit-learn (imputers, encoders, scalers) | âœ… Implementado | [PREPROCESSING.md](PREPROCESSING.md) |
| Machine Learning | Scikit-learn (KMeans, DBSCAN, IsolationForest) | âœ… Implementado | [src/ml/](src/ml/README.md) |
| Change Point Detection | Ruptures | ğŸš§ PrÃ³xima Fase | - |
| ValidaÃ§Ã£o | Pydantic | ğŸš§ PrÃ³xima Fase | - |
| Observabilidade ML | MLflow | ğŸš§ PrÃ³xima Fase | - |
| API | FastAPI | ğŸ“… Planejado | - |
| LLM | DSPY, Agno | ğŸ“… Planejado | - |

### Legenda
- âœ… Implementado e documentado
- ğŸš§ PrÃ³xima fase (segundo planejamento)
- ğŸ“… Planejado (MÃ³dulo 2)

## DocumentaÃ§Ã£o

### Guias de Uso
- [USAGE.md](USAGE.md) - Guia de uso do pipeline completo
- [PREPROCESSING.md](PREPROCESSING.md) - Guia completo de prÃ©-processamento (todos os 5 tipos de dados + Scikit-learn)

### DocumentaÃ§Ã£o dos MÃ³dulos
- [src/extraction/README.md](src/extraction/README.md) - MÃ³dulo de extraÃ§Ã£o
- [src/preprocessing/README.md](src/preprocessing/README.md) - MÃ³dulo de prÃ©-processamento
- [src/ml/README.md](src/ml/README.md) - MÃ³dulo de Machine Learning (Clustering + Anomaly Detection)
- [cli/README.md](cli/README.md) - Ferramentas CLI

### DocumentaÃ§Ã£o TÃ©cnica
- [docs/](docs/) - DocumentaÃ§Ã£o detalhada (arquitetura, API)

## Testes

```bash
# Executar testes de extraÃ§Ã£o
uv run python tests/test_extraction/test_basic.py

# Executar testes de prÃ©-processamento (23 testes)
uv run pytest tests/preprocessing/ -v

# Rodar exemplos prÃ¡ticos
uv run python examples/preprocessing_example.py
```

**Cobertura de Testes:**
- âœ… ExtraÃ§Ã£o: Testado manualmente
- âœ… PrÃ©-processamento: 23 testes unitÃ¡rios (100% passando)
- â³ ML Pipeline: Planejado
- â³ API: Planejado

## ConfiguraÃ§Ã£o

O arquivo `config.yaml` centraliza todas as configuraÃ§Ãµes do projeto:
- DiretÃ³rios de dados
- ParÃ¢metros de extraÃ§Ã£o
- ConfiguraÃ§Ãµes de ML
- ConfiguraÃ§Ãµes de API e LLM

## Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:
- Reporte bugs atravÃ©s das issues
- Sugira novas funcionalidades
- Envie pull requests