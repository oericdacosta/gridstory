# MLFlow Setup e M√©tricas de ML - gridstory

## ‚úÖ Implementa√ß√£o Conclu√≠da

Este documento resume a integra√ß√£o completa do **MLFlow** e **m√©tricas de avalia√ß√£o** para o pipeline de Machine Learning do gridstory.

---

## üì¶ O Que Foi Implementado

### 1. M√©tricas de Avalia√ß√£o Completas (`src/ml/metrics.py`)

#### M√©tricas de Clustering
- **Silhouette Score**: Coes√£o vs separa√ß√£o dos clusters [-1, 1]
- **Davies-Bouldin Index**: Compacidade vs separa√ß√£o [0, ‚àû), menor √© melhor
- **Calinski-Harabasz Score**: Ratio between/within variance [0, ‚àû), maior √© melhor
- **In√©rcia**: Soma das dist√¢ncias aos centr√≥ides (K-Means espec√≠fico)

#### M√©tricas de Anomaly Detection
- **n_anomalies**: N√∫mero total de anomalias detectadas
- **anomaly_rate**: Taxa de anomalias (%)
- **score_mean/std**: Estat√≠sticas dos scores de anomalia
- **anomaly_score_mean**: M√©dia dos scores das anomalias
- **normal_score_mean**: M√©dia dos scores dos pontos normais

#### Fun√ß√µes Utilit√°rias
- `calculate_clustering_metrics()`: Calcula todas as m√©tricas de clustering
- `calculate_anomaly_metrics()`: Calcula m√©tricas de anomaly detection
- `calculate_cluster_statistics()`: Estat√≠sticas descritivas por cluster
- `evaluate_clustering_quality()`: Avalia qualidade (excellent, good, fair, poor)

---

### 2. Integra√ß√£o MLFlow (`src/ml/tracking.py`)

#### Funcionalidades Principais
- **setup_mlflow()**: Configura√ß√£o inicial do MLFlow (autolog **desabilitado** por padr√£o)
- **track_clustering_run()**: Tracka runs de clustering (K-Means, DBSCAN)
- **track_anomaly_detection_run()**: Tracka runs de anomaly detection
- **track_pipeline_run()**: Tracka pipeline completo + salva artefatos CSV
- **compare_runs()**: Compara m√∫ltiplos runs
- **get_best_run()**: Encontra melhor run baseado em m√©trica

> **Por que autolog est√° desabilitado?** O autolog do scikit-learn cria um child run para cada `fit()`, gerando centenas de runs com `conda.yaml`, `requirements.txt` e pickles de modelo ‚Äî mais de 10 mil arquivos por an√°lise. As m√©tricas relevantes s√£o logadas manualmente com mais controle.

#### O Que √© Trackeado
**Par√¢metros (Inputs)**:
- `n_clusters`, `eps`, `min_samples`, `contamination`
- `random_state`, `scaler_type`, `structural_filter_threshold`
- `cluster_features`, `anomaly_features`

**M√©tricas (Outputs)** ‚Äî todas calculadas **por piloto**:
- `clustering_silhouette_mean`, `clustering_silhouette_std`
- `clustering_davies_bouldin_mean`
- `clustering_calinski_harabasz_mean`
- `clustering_n_drivers_evaluated`
- `clustering_n_structural_filtered`
- `clustering_driver_VER_silhouette`, `clustering_driver_HAM_silhouette`, etc.
- M√©tricas DBSCAN: `clustering_dbscan_n_noise`, `clustering_dbscan_silhouette_mean`
- Anomaly detection: `anomaly_n_anomalies`, `anomaly_anomaly_rate`, `anomaly_score_mean`

**Artefatos** (vis√≠veis na aba **Artifacts** do MLFlow UI):
- `results/laps_clustered.csv` ‚Äî voltas com `cluster_label` por piloto
- `results/laps_anomalies.csv` ‚Äî voltas com `is_anomaly` e `anomaly_score`
- `results/cluster_statistics.csv` ‚Äî m√©dia/std por cluster
- `results/per_driver_metrics.csv` ‚Äî silhouette, DB, CH por piloto

---

### 3. Pipeline Atualizado (`src/ml/pipeline.py`)

**Fun√ß√£o `run_race_analysis()` agora inclui**:
- Par√¢metro `enable_mlflow`: Habilita tracking
- Par√¢metro `experiment_name`: Nome do experimento
- Par√¢metro `run_name`: Nome do run (opcional)
- Retorna `mlflow_run_id` nos resultados
- Retorna `clustering_metrics` e `anomaly_metrics` completas

---

### 4. Tracking Config-Driven

O tracking MLFlow √© habilitado diretamente no `config.yaml`:

```yaml
mlflow:
  enabled: true                    # habilitar/desabilitar sem mudar c√≥digo
  tracking_uri: "file:./mlruns"
  experiment_prefix: "F1"          # experimento: F1_{year}_Round_{round:02d}
```

Com `enabled: true`, cada execu√ß√£o de `uv run python cli/pipeline.py 2025 1` cria automaticamente um run no MLFlow com m√©tricas, par√¢metros e artefatos CSV.

---

### 5. Exemplo Completo (`examples/mlflow_example.py`)

**Script de demonstra√ß√£o com 3 exemplos**:
1. **Basic Tracking**: Tracking b√°sico de uma an√°lise completa
2. **Experimentation**: Experimenta√ß√£o com diferentes hiperpar√¢metros
3. **Comparison**: Compara√ß√£o de runs e sele√ß√£o do melhor

```bash
# Executar exemplos
uv run python examples/mlflow_example.py

# Depois visualizar no MLFlow UI
mlflow ui
# Acesse: http://localhost:5000
```

---

### 6. Documenta√ß√£o Completa (`src/ml/README.md`)

**Se√ß√µes adicionadas**:
- Se√ß√£o 4: M√©tricas de Avalia√ß√£o
  - 4.1. M√©tricas de Clustering
  - 4.2. M√©tricas de Anomaly Detection
- Se√ß√£o 5: MLFlow Tracking
  - 5.1. Vis√£o Geral
  - 5.2. Setup Inicial
  - 5.3. O Que √© Trackeado
  - 5.4. Tracking no Pipeline
  - 5.5. CLI de An√°lise
  - 5.6. Comparar Experimentos
  - 5.7. Tracking Manual (Avan√ßado)
  - 5.8. Fluxo de Trabalho Recomendado
  - 5.9. Interpreta√ß√£o de Resultados

---

## üöÄ Como Usar

### Setup Inicial (Primeira Vez)

```bash
# 1. Instalar depend√™ncias (MLFlow j√° inclu√≠do)
uv sync

# 2. Habilitar MLFlow no config.yaml (j√° vem habilitado por padr√£o)
# mlflow.enabled: true

# 3. Rodar pipeline ‚Äî tracking acontece automaticamente
uv run python cli/pipeline.py 2025 1
```

### Visualizar Resultados

```bash
# Iniciar MLFlow UI (sempre use uv run)
uv run mlflow ui

# Acessar: http://localhost:5000
```

### Exemplo Program√°tico

```python
from src.ml import setup_mlflow, run_race_analysis
import pandas as pd

# 1. Carregar dados
laps_df = pd.read_parquet('data/processed/races/2025/round_01/laps_processed.parquet')

# 2. Setup MLFlow
setup_mlflow("F1_2025_Round_01")

# 3. Executar an√°lise COM tracking
results = run_race_analysis(
    laps_df=laps_df,
    analysis_type='all',
    enable_mlflow=True,
    experiment_name='F1_2025_Round_01',
    run_name='Full_Analysis',
)

# 4. Ver resultados
print(f"MLFlow Run ID: {results['mlflow_run_id']}")
print(results['clustering_metrics'])
print(results['anomaly_metrics'])
```

---

## üìä M√©tricas: Como Interpretar

### Clustering (K-Means)

**Bom clustering**:
- ‚úÖ Silhouette > 0.5
- ‚úÖ Davies-Bouldin < 1.0
- ‚úÖ Clusters fazem sentido no contexto F1

**Clustering ruim**:
- ‚ùå Silhouette < 0.25
- ‚ùå Davies-Bouldin > 2.0
- üîß A√ß√µes: Ajustar features, tentar DBSCAN, revisar pr√©-processamento

### Anomaly Detection

**Configura√ß√£o adequada**:
- ‚úÖ Taxa de anomalias: 2-5% (esperado para corrida limpa)
- ‚úÖ Anomalias correspondem a eventos reais
- ‚úÖ Scores das anomalias << scores dos normais

**Ajustes necess√°rios**:
- Taxa muito alta (>10%): Reduzir `contamination`
- Taxa muito baixa (<1%): Aumentar `contamination`
- Anomalias n√£o fazem sentido: Revisar features

---

## üî¨ Fluxo de Trabalho Recomendado

### 1. Rodar pipeline com tracking

```bash
# MLFlow habilitado via config.yaml (mlflow.enabled: true)
uv run python cli/pipeline.py 2025 1
```

### 2. An√°lise de Resultados (MLFlow UI)

```bash
# Iniciar UI
uv run mlflow ui

# Acesse http://localhost:5000
# Compare runs, visualize m√©tricas, identifique melhor configura√ß√£o
# Na aba "Artifacts" de cada run: laps_clustered.csv, per_driver_metrics.csv, tire_cliffs.csv, etc.
```

### 4. Compara√ß√£o Program√°tica

```python
from src.ml import compare_runs, get_best_run

# Ver todos os runs
comparison = compare_runs("F1_2025_Round_01")
print(comparison)

# Encontrar melhor configura√ß√£o
best = get_best_run("F1_2025_Round_01", "silhouette_score")
print(f"Melhor: {best['params']}")
```

### 5. Produ√ß√£o (Melhor Modelo)

```python
import mlflow

# Carregar melhor modelo
best_run_id = best['run_id']
model = mlflow.sklearn.load_model(f"runs:/{best_run_id}/model")

# Usar em produ√ß√£o
predictions = model.predict(new_data)
```

---

## üìÅ Estrutura de Arquivos

```
src/ml/
‚îú‚îÄ‚îÄ pipeline.py             # run_race_analysis() ‚Äî clustering + anomaly + changepoint + mlflow
‚îú‚îÄ‚îÄ clustering.py           # K-Means e DBSCAN por piloto
‚îú‚îÄ‚îÄ anomaly_detection.py    # Isolation Forest
‚îú‚îÄ‚îÄ change_point.py         # Ruptures/PELT ‚Äî tire cliffs
‚îú‚îÄ‚îÄ metrics.py              # M√©tricas de avalia√ß√£o (silhouette, Davies-Bouldin, etc.)
‚îú‚îÄ‚îÄ tracking.py             # Integra√ß√£o MLFlow
‚îî‚îÄ‚îÄ README.md               # Documenta√ß√£o completa

cli/
‚îú‚îÄ‚îÄ pipeline.py             # √önico ponto de entrada do pipeline completo
‚îî‚îÄ‚îÄ ruptures_analysis.py    # Calibra√ß√£o de penalty (penalty-search)

mlruns/                     # ‚úÖ Gerado automaticamente pelo MLFlow
‚îî‚îÄ‚îÄ [experiments]/
    ‚îî‚îÄ‚îÄ [runs]/
        ‚îú‚îÄ‚îÄ metrics/
        ‚îú‚îÄ‚îÄ params/
        ‚îú‚îÄ‚îÄ artifacts/
        ‚îî‚îÄ‚îÄ meta.yaml
```

---

## ‚úÖ Checklist de Valida√ß√£o

### M√©tricas Implementadas
- [x] Silhouette Score
- [x] Davies-Bouldin Index
- [x] Calinski-Harabasz Score
- [x] In√©rcia (K-Means)
- [x] M√©tricas de anomaly detection
- [x] Estat√≠sticas por cluster
- [x] Avalia√ß√£o qualitativa de clustering

### MLFlow Implementado
- [x] Setup e configura√ß√£o
- [x] Tracking de clustering (m√©tricas por piloto)
- [x] Tracking de anomaly detection
- [x] Tracking de pipeline completo
- [x] Autolog **desabilitado** (evita 10k+ child runs)
- [x] Compara√ß√£o de runs
- [x] Sele√ß√£o do melhor run
- [x] Artefatos CSV vis√≠veis na UI (laps_clustered, laps_anomalies, per_driver_metrics)
- [x] Logging de m√©tricas por piloto (silhouette, davies-bouldin por driver)

### C√≥digo e Documenta√ß√£o
- [x] M√≥dulo de m√©tricas (`metrics.py`)
- [x] M√≥dulo de tracking (`tracking.py`)
- [x] Pipeline atualizado com MLFlow
- [x] Tracking config-driven via pipeline.py
- [x] Exemplos funcionais
- [x] Documenta√ß√£o completa
- [x] README atualizado

### Depend√™ncias
- [x] MLFlow instalado (`>=3.10.0rc0`)
- [x] Compatibilidade com PyArrow 23+
- [x] `uv sync --prerelease=allow` funcional

---

## üéØ Pr√≥ximos Passos

### Imediato (J√° Pode Fazer)
1. ‚úÖ **Executar an√°lises com tracking**
   ```bash
   uv run python -m cli.ml_analysis --year 2025 --round 1 --mlflow
   ```

2. ‚úÖ **Visualizar no MLFlow UI**
   ```bash
   uv run mlflow ui
   ```

3. ‚úÖ **Experimentar com diferentes hiperpar√¢metros**
   - Variar `contamination` (0.03, 0.05, 0.10)
   - Variar `n_clusters` (auto-detect vs fixo)
   - Variar `scaler_type` (standard vs robust)

4. ‚úÖ **Comparar resultados e selecionar melhor configura√ß√£o**

### Curto Prazo (Pr√≥ximas Features)
- [ ] Visualiza√ß√µes (matplotlib) com tracking de plots
- [ ] Testes unit√°rios para m√©tricas
- [ ] Valida√ß√£o cruzada para hiperpar√¢metros

### M√©dio Prazo (Integra√ß√£o Completa)
- [ ] Integrar tracking de Ruptures
- [ ] Adicionar tracking de LLM (quando implementar DSPY/Agno)
- [ ] Dashboard customizado de m√©tricas
- [ ] Alertas autom√°ticos de qualidade de modelo

---

## üìö Refer√™ncias

- **Documenta√ß√£o MLFlow**: https://mlflow.org/docs/latest/
- **Documenta√ß√£o do M√≥dulo**: [src/ml/README.md](src/ml/README.md)
- **Scikit-learn Metrics**: https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation
- **C√≥digo-fonte**: `src/ml/`

---

## üêõ Troubleshooting

### MLFlow n√£o est√° logando m√©tricas

**Problema**: `autolog` n√£o captura m√©tricas de clustering

**Solu√ß√£o**: M√©tricas de clustering n√£o supervisionado requerem logging manual (j√° implementado):
```python
from sklearn.metrics import silhouette_score
import mlflow

with mlflow.start_run():
    score = silhouette_score(X, labels)
    mlflow.log_metric("silhouette_score", score)
```

### Experimentos n√£o aparecem no UI

**Solu√ß√µes**:
1. Verificar se `mlflow ui` est√° rodando no diret√≥rio correto
2. Verificar se `tracking_uri` est√° configurado: `file:./mlruns`
3. Verificar se experimento existe: `mlflow.get_experiment_by_name(name)`

### M√©tricas retornam None

**Causas comuns**:
- Menos de 2 clusters
- Clusters com 1 amostra apenas
- Dados insuficientes ap√≥s filtrar ru√≠do (DBSCAN)

**Solu√ß√£o**: Verificar `n_clusters` e `n_samples` nas m√©tricas retornadas

### Conflito de depend√™ncias MLFlow/PyArrow

**Solu√ß√£o**: Usar vers√£o rc do MLFlow
```bash
uv sync --prerelease=allow
```

---

## ‚ú® Conclus√£o

Voc√™ agora tem:
- ‚úÖ **M√©tricas completas** para avaliar qualidade do ML
- ‚úÖ **MLFlow tracking** para rastrear experimentos
- ‚úÖ **CLI dedicado** para an√°lise com tracking
- ‚úÖ **Exemplos funcionais** para aprender
- ‚úÖ **Documenta√ß√£o completa** para refer√™ncia

**Pronto para:**
1. Avaliar corretamente seus modelos de ML
2. Experimentar com diferentes configura√ß√µes
3. Comparar resultados e escolher a melhor abordagem
4. Avan√ßar para Ruptures com confian√ßa

**Pr√≥ximo passo sugerido:**
```bash
# 1. Rodar pipeline (MLFlow habilitado via config.yaml)
uv run python cli/pipeline.py 2025 1

# 2. Visualizar resultados
uv run mlflow ui

# 3. Verificar aba "Artifacts" de cada run para ver os CSVs gerados
```

---

**Data de Implementa√ß√£o**: 2026-02-16
**Vers√£o do Projeto**: 0.1.0
**MLFlow**: 3.10.0rc0
